Hi, and welcome back
to this lesson on Elastic Map Reduce,
also known as EMR.
Now, Elastic Map Reduce is a big data platform.
You may have heard of big data before,
and it's usually petabytes of data
that requires large-scale parallel data processing,
and it's used for petabyte scale interactive analysis.
Now, Elastic Map Reduce supports
multiple different types of data.
For instance, structured data
like financial transaction data,
semi-structured data,
which could be text or documentation,
and completely unstructured data,
which could be application logs or click-stream data.
Example use cases include data analysis and processing.
For instance, processing genomic data
using statistical algorithms and predictive models
to discover hidden patterns and find correlations.
What about analyzing click-stream data
to understand customer preferences or market trends,
or performing log processing on log data
generated by your applications.
Now, EMR can extract data
from a variety of sources
like S3, DynamoDB, or Redshift,
and it can also be used to analyze events
from streaming data sources
in real time using Kinesis.
It also supports popular open-source frameworks
like Apache Spark, Apache Hive, Presto, or Hadoop.
And that means that you can build
and run applications using these frameworks
and they'll be able to interact with Elastic Map Reduce.
Now, the great thing about using EMR
is that it is essentially
a fully managed big data solution,
and AWS is gonna do all the heavy lifting for you.
So that means there's no need to worry
about provisioning and managing infrastructure,
or configuring and managing open-source applications.
You don't need to worry about capacity planning,
and it can scale dynamically out and in
as required by your workload,
and it's optimized for performance.
And AWS claim that it's faster
and less than 50% of the cost
of deploying your own big data solution on-premises.
So for the exam, know that EMR
is a fully managed big data solution.
It supports open-source technologies
like Apache Spark, Apache Hive, Presto, and Hadoop.
It supports petabyte scale,
parallel data processing and analytics
for structured, semi-structured,
and unstructured data.
And use cases include finding patterns in genomic data,
identifying preferences from click-stream data,
or analyzing application log data.
Well, that is all for this lesson,
and if you'd like to move on,
I will see you in the next one.
Thank you.